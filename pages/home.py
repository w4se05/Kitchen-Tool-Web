"""Object detection demo with MobileNet SSD.
This model and code are based on
https://github.com/robmarkcole/object-detection-app
"""

import time
import logging
import queue
from pathlib import Path
from typing import List, NamedTuple
import os
import aiortc
import av
import cv2
import numpy as np
import pandas as pd
import streamlit as st
from streamlit_webrtc import WebRtcMode, webrtc_streamer, RTCConfiguration
from streamlit_webrtc import __version__ as st_webrtc_version
from ultralytics import YOLO
from utils.download import download_file

# ==========================================
# 1. GLOBAL CONFIG & CONSTANTS (Run once)
# ==========================================
# C·∫•u h√¨nh STUN server c·ªßa Google (Mi·ªÖn ph√≠ & ·ªîn ƒë·ªãnh)
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {"urls": ["stun:stun1.l.google.com:19302"]},
        {"urls": ["stun:stun2.l.google.com:19302"]},
        {"urls": ["stun:stun3.l.google.com:19302"]},
        {"urls": ["stun:stun4.l.google.com:19302"]},
    ]}
)

HERE = Path(__file__).parent
ROOT = HERE.parent

logger = logging.getLogger(__name__)

MODEL_URL = "https://github.com/robmarkcole/object-detection-app/raw/master/model/MobileNetSSD_deploy.caffemodel"
MODEL_LOCAL_PATH = "../models/best_kc_tool.pt"
CLASSES = [
    "Spoon", "Spoon (Wooden)", "Fork", "bird", "boat", "bottle", "bus", "car", "cat", 
    "chair", "cow", "diningtable", "dog", "horse", "Pot", "person", "pottedplant", 
    "sheep", "sofa", "tvmonitor"
]

class Detection(NamedTuple):
    class_id: int
    label: str
    score: float
    box: np.ndarray
    note: str

@st.cache_resource
def generate_label_colors():
    return np.random.uniform(0, 255, size=(len(CLASSES), 3))

COLORS = generate_label_colors()

# download_file(MODEL_URL, MODEL_LOCAL_PATH, expected_size=23147564)

# Load model globally so it's fast
NET = YOLO(Path(MODEL_LOCAL_PATH))

# ==========================================
# 2. MAIN APP FUNCTION
# ==========================================
def app():
    # --- 1. CH√àN CSS ƒê·ªÇ L√ÄM ƒê·∫∏P B·∫¢NG K·∫æT QU·∫¢ ---
    st.markdown("""
    <style>
        /* Style cho b·∫£ng k·∫øt qu·∫£ */
        table.custom-table {
            width: 100%;
            border-collapse: collapse;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            font-family: sans-serif;
        }
        
        /* Header c·ªßa b·∫£ng */
        table.custom-table thead th {
            background-color: #FF4B4B; /* M√†u ƒë·ªè ch·ªß ƒë·∫°o */
            color: white;
            padding: 12px 15px;
            text-align: left;
            font-weight: bold;
            font-size: 16px;
        }
        
        /* C√°c d√≤ng d·ªØ li·ªáu */
        table.custom-table tbody td {
            padding: 10px 15px;
            border-bottom: 1px solid #eeeeee;
            color: #333;
            vertical-align: middle;
        }
        
        /* Hi·ªáu ·ª©ng khi di chu·ªôt v√†o d√≤ng */
        table.custom-table tbody tr:hover {
            background-color: #f8f9fa;
        }
        
        /* N√∫t b·∫•m Link */
        a.result-btn {
            display: inline-block;
            padding: 5px 12px;
            background-color: #007bff; /* M√†u xanh n√∫t b·∫•m */
            color: white !important;
            text-decoration: none;
            border-radius: 20px;
            font-size: 13px;
            font-weight: 600;
            transition: background 0.2s;
        }
        a.result-btn:hover {
            background-color: #0056b3;
        }
        
        /* Badge ƒëi·ªÉm s·ªë */
        span.score-badge {
            background-color: #e9ecef;
            color: #495057;
            padding: 4px 8px;
            border-radius: 4px;
            font-weight: bold;
            font-size: 14px;
        }
    </style>
    """, unsafe_allow_html=True)
    # -------------------------------------------

    st.title("üìπ Object Detection Live Feed")
    st.caption("Real-time MobileNet SSD Object Detection")

    # --- A. LOGIC AUTOMATICALLY TURN ON CAM  ---
    should_auto_start = st.session_state.get("auto_start_trigger", False)
    
    if should_auto_start:
        desired_state = True
    else:
        desired_state = None
    # --------------------------------

    # --- B. CREATE LAYOUT ---
    col1, col2 = st.columns([0.65, 0.35])

    # --- C. CONTROLS AND CALLBACK (IMPORTANT) ---
    with col2:
        st.write("#### Controls")
        score_threshold = st.slider("Score threshold", 0.0, 1.0, 0.5, 0.05)
        
        # Initialize queue for this session
        result_queue: "queue.Queue[List[Detection]]" = queue.Queue()

    # ---------------------------------------------------------
    # DEFINE CALLBACK (Must be inside app() to see 'score_threshold')
    # ---------------------------------------------------------
    def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
        image = frame.to_ndarray(format="bgr24") # (480, 640, 3)

        # We need to convert the image to RGB before passing to model
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        # Run inference
        results = NET.predict(source=image_rgb, conf=score_threshold, verbose=False)
        h, w = image.shape[:2]
        output = results[0].boxes.cpu().numpy()  # (N, 6) format: [x1, y1, x2, y2, score, class]

        # Draw boxes
        for detection in output:
            caption = f"{detection.cls[0]}: {round(detection.conf[0] * 100, 2)}%"
            color = COLORS[int(detection.cls[0])]
            xmin, ymin, xmax, ymax = detection.xyxy[0].astype("int")

            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)
            cv2.putText(
                image, caption,
                (xmin, ymin - 15 if ymin - 15 > 15 else ymin + 15),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2,
            )

        # result_queue.put(detections)
        return av.VideoFrame.from_ndarray(image, format="bgr24")

    # --- D. DISPLAY CAMERA ---
    with col1:
        st.write("#### Live Camera")
        webrtc_ctx = webrtc_streamer(
            key="object-detection",
            mode=WebRtcMode.SENDRECV,
            rtc_configuration=RTC_CONFIGURATION,
            video_frame_callback=video_frame_callback,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
            desired_playing_state=desired_state # T·ª± ƒë·ªông b·∫≠t cam n·∫øu c√≥ t√≠n hi·ªáu
        )
        # --- LOGIC RESET: CH·ªà T·∫ÆT TRIGGER KHI CAM ƒê√É CH·∫†Y ---
        if should_auto_start and webrtc_ctx.state.playing:
            # L√∫c n√†y m·ªõi t·∫Øt l·ªánh ƒëi ƒë·ªÉ tr·∫£ l·∫°i quy·ªÅn ki·ªÉm so√°t cho n√∫t Stop
            st.session_state["auto_start_trigger"] = False
            st.rerun() # Rerun m·ªôt c√°i ƒë·ªÉ c·∫≠p nh·∫≠t giao di·ªán

    # --- E. DISPLAY RESULT ---
    with col2:
        st.write("#### Results")
        if st.checkbox("Show detected labels", value=True):
            if webrtc_ctx.state.playing:
                labels_placeholder = st.empty()
                
                while True:
                    try:
                        result = result_queue.get(timeout=1.0)
                        while not result_queue.empty():
                            result = result_queue.get_nowait()
                    except queue.Empty:
                        result = None

                    if result is not None:
                        df = pd.DataFrame(result)
                        if not df.empty:
                            df['Action'] = df['label'].apply(
                                lambda x: f'<a href="./?nav=Wiki%20Search&tab={x}" target="_self" class="result-btn">Wiki ‚ûú</a>'
                            )
                            df['Confidence'] = df['score'].apply(
                                lambda x: f'<span class="score-badge">{x*100:.1f}%</span>'
                            )
                            df['Object'] = df['label'].str.capitalize()

                            # Display result
                            display_df = df[["Object", "Confidence", "Action"]]

                            # Render HTML with class 'custom-table' for CSS
                            html_table = display_df.to_html(escape=False, index=False, classes="custom-table")
                            
                            # Border style
                            labels_placeholder.markdown(html_table, unsafe_allow_html=True)
                        else:
                            labels_placeholder.info("Waiting for object...")
                    
                    time.sleep(0.1)

    # Footer (Full Width)
    st.markdown("---")
    st.caption("Powered by 5 anh em siu nhan.")